{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Копия блокнота \"homework-practice-08-random-features.ipynb\"",
      "provenance": [],
      "collapsed_sections": [
        "3bo6zVTdSvfx",
        "Ot1bTtQUUbkZ"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYp0bXOFK-hP"
      },
      "source": [
        "# Машинное обучение, ФКН ВШЭ\n",
        "\n",
        "## Практическое задание 8. Метод опорных векторов и аппроксимация ядер\n",
        "\n",
        "### Общая информация\n",
        "Дата выдачи: 1.10.2021\n",
        "\n",
        "Мягкий дедлайн: 17.10.2021 23:59 МСК\n",
        "\n",
        "Жесткий дедлайн: 24.10.2021 23:59 МСК (1 неделя -- минус балл)\n",
        "\n",
        "### Оценивание и штрафы\n",
        "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимальная оценка за работу (без учёта бонусов) — 10 баллов.\n",
        "\n",
        "Сдавать задание после указанного жёсткого срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
        "\n",
        "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
        "\n",
        "Неэффективная реализация кода может негативно отразиться на оценке.\n",
        "\n",
        "### Формат сдачи\n",
        "Загрузите решение в свой репозиторий на github и поделитесь [ссылкой на решение в форме](https://forms.gle/ZzCaqRj6bmfpSpyL7). Не забудьте дать доступ к Вашему репозиторию, что у преподавателей была возмоожность проверить работу."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY8vT0W_K-hR"
      },
      "source": [
        "### О задании\n",
        "\n",
        "На занятиях мы подробно обсуждали метод опорных векторов (SVM). В базовой версии в нём нет чего-то особенного — мы всего лишь используем специальную функцию потерь, которая не требует устремлять отступы к бесконечности; ей достаточно, чтобы отступы были не меньше +1. Затем мы узнали, что SVM можно переписать в двойственном виде, который, позволяет заменить скалярные произведения объектов на ядра. Это будет соответствовать построению модели в новом пространстве более высокой размерности, координаты которого представляют собой нелинейные модификации исходных признаков.\n",
        "\n",
        "Ядровой SVM, к сожалению, довольно затратен по памяти (нужно хранить матрицу Грама размера $d \\times d$) и по времени (нужно решать задачу условной оптимизации с квадратичной функцией, а это не очень быстро). Мы обсуждали, что есть способы посчитать новые признаки $\\tilde \\varphi(x)$ на основе исходных так, что скалярные произведения этих новых $\\langle \\tilde \\varphi(x), \\tilde \\varphi(z) \\rangle$ приближают ядро $K(x, z)$.\n",
        "\n",
        "Мы будем исследовать аппроксимации методом Random Fourier Features (RFF, также в литературе встречается название Random Kitchen Sinks) для гауссовых ядер. Будем использовать формулы, которые немного отличаются от того, что было на лекциях (мы добавим сдвиги внутрь тригонометрических функций и будем использовать только косинусы, потому что с нужным сдвигом косинус превратится в синус):\n",
        "$$\\tilde \\varphi(x) = (\n",
        "\\cos (w_1^T x + b_1),\n",
        "\\dots,\n",
        "\\cos (w_n^T x + b_n)\n",
        "),$$\n",
        "где $w_j \\sim \\mathcal{N}(0, 1/\\sigma^2)$, $b_j \\sim U[-\\pi, \\pi]$.\n",
        "\n",
        "На новых признаках $\\tilde \\varphi(x)$ мы будем строить любую линейную модель.\n",
        "\n",
        "Можно считать, что это некоторая новая парадигма построения сложных моделей. Можно направленно искать сложные нелинейные закономерности в данных с помощью градиентного бустинга или нейронных сетей, а можно просто нагенерировать большое количество случайных нелинейных признаков и надеяться, что быстрая и простая модель (то есть линейная) сможет показать на них хорошее качество. В этом задании мы изучим, насколько работоспособна такая идея.\n",
        "\n",
        "### Алгоритм\n",
        "\n",
        "Вам потребуется реализовать следующий алгоритм:\n",
        "1. Понизить размерность выборки до new_dim с помощью метода главных компонент.\n",
        "2. Для полученной выборки оценить гиперпараметр $\\sigma^2$ с помощью эвристики (рекомендуем считать медиану не по всем парам объектов, а по случайному подмножеству из где-то миллиона пар объектов): $$\\sigma^2 = \\text{median}_{i, j = 1, \\dots, \\ell, i \\neq j} \\left\\{\\sum_{k = 1}^{d} (x_{ik} - x_{jk})^2 \\right\\}$$\n",
        "3. Сгенерировать n_features наборов весов $w_j$ и сдвигов $b_j$.\n",
        "4. Сформировать n_features новых признаков по формулам, приведённым выше.\n",
        "5. Обучить линейную модель (логистическую регрессию или SVM) на новых признаках.\n",
        "6. Повторить преобразования (PCA, формирование новых признаков) к тестовой выборке и применить модель."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_sGunb7K-hS"
      },
      "source": [
        "Тестировать алгоритм мы будем на данных Fashion MNIST. Ниже код для их загрузки и подготовки."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyG6dBfjK-hS",
        "outputId": "d62f6fb3-4c9b-4fd7-df35-6f260755c82b"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import fashion_mnist\n",
        "(x_train_pics, y_train), (x_test_pics, y_test) = fashion_mnist.load_data()\n",
        "x_train = x_train_pics.reshape(x_train_pics.shape[0], -1)\n",
        "x_test = x_test_pics.reshape(x_test_pics.shape[0], -1)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJNN55F7K-hT"
      },
      "source": [
        "__Задание 1. (5 баллов)__\n",
        "\n",
        "Реализуйте алгоритм, описанный выше. Можете воспользоваться шаблоном класса ниже или написать свой интерфейс.\n",
        "\n",
        "Ваша реализация должна поддерживать следующие опции:\n",
        "1. Возможность задавать значения гиперпараметров new_dim (по умолчанию 50) и n_features (по умолчанию 1000).\n",
        "2. Возможность включать или выключать предварительное понижение размерности с помощью метода главных компонент.\n",
        "3. Возможность выбирать тип линейной модели (логистическая регрессия или SVM с линейным ядром).\n",
        "\n",
        "Протестируйте на данных Fashion MNIST, сформированных кодом выше. Если на тесте у вас получилась доля верных ответов не ниже 0.84 с гиперпараметрами по умолчанию, то вы всё сделали правильно."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP8yepx8K-hT"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "import timeit\n",
        "\n",
        "\n",
        "class RFFPipeline(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='logreg'):\n",
        "        \"\"\"        \n",
        "        Implements pipeline, which consists of PCA decomposition,\n",
        "        Random Fourier Features approximation and linear classification model.\n",
        "        \n",
        "        n_features, int: amount of synthetic random features generated with RFF approximation.\n",
        "\n",
        "        new_dim, int: PCA output size.\n",
        "        \n",
        "        use_PCA, bool: whether to include PCA preprocessing.\n",
        "        \n",
        "        classifier, string: either 'svm' or 'logreg', a linear classification model to use on top of pipeline.\n",
        "        \n",
        "        Feel free to edit this template for your preferences.    \n",
        "        \"\"\"\n",
        "        self.n_features = n_features\n",
        "        self.use_PCA = use_PCA\n",
        "        self.new_dim = new_dim\n",
        "        self.classifier = classifier\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
        "        \"\"\"\n",
        "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
        "        self.normalizer = Normalizer()\n",
        "        start = timeit.default_timer()\n",
        "        X = self.normalizer.fit_transform(X)\n",
        "        if self.use_PCA:\n",
        "          self.pca = PCA(n_components=self.new_dim)\n",
        "          X = self.pca.fit_transform(X)\n",
        "        else:\n",
        "          self.new_dim = X.shape[1]\n",
        "        self.sigma = 1 / self.__get_sigma__(X) \n",
        "        self.w = np.random.normal(0, self.sigma, [self.new_dim, self.n_features])\n",
        "        self.b = np.random.uniform(-np.pi, np.pi, self.n_features)\n",
        "        X_new = np.cos(X@self.w + self.b)\n",
        "        if self.classifier == 'logreg':\n",
        "          self.classifier = LogisticRegression(random_state=0, verbose=False)\n",
        "        else:\n",
        "          self.classifier = SVC(random_state=0, verbose=True)\n",
        "\n",
        "        self.classifier = self.classifier.fit(X_new, y)\n",
        "\n",
        "        stop = timeit.default_timer()\n",
        "\n",
        "        print(f'RFFP (PCA: {self.use_PCA}, Time: ', stop - start)  \n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"\n",
        "        Apply pipeline to obtain scores for input data.\n",
        "        \"\"\"\n",
        "        X = self.normalizer.transform(X)\n",
        "        if self.use_PCA:\n",
        "         X = self.pca.transform(X)\n",
        "        X = np.cos(X@self.w + self.b)\n",
        "\n",
        "        pred = self.classifier.predict_proba(X)\n",
        "        return pred\n",
        "\n",
        "        \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Apply pipeline to obtain discrete predictions for input data.\n",
        "        \"\"\"\n",
        "        X = self.normalizer.transform(X)\n",
        "        if self.use_PCA:\n",
        "         X = self.pca.transform(X)\n",
        "        X = np.cos(X@self.w + self.b)\n",
        "\n",
        "        pred = self.classifier.predict(X)\n",
        "        return pred\n",
        "\n",
        "    def __get_sigma__(self, X, num_pairs:int = 1000000):\n",
        "\n",
        "    '''\n",
        "    Function to calculate sigma\n",
        "    '''\n",
        "      med_values = []\n",
        "      for num_pairs in range(num_pairs):\n",
        "        i, j = np.random.randint(X.shape[0], size=2)\n",
        "        if i == j:\n",
        "          continue\n",
        "        dif = 0\n",
        "        for k in range(X.shape[1]):\n",
        "          dif += (X[i][k] - X[j][k])**2\n",
        "        med_values.append(dif)\n",
        "      return np.median(med_values)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhg6U6mkzHqu",
        "outputId": "00ebae1c-4fdf-4782-aa84-bdadb43e3b34"
      },
      "source": [
        "rff = RFFPipeline()\n",
        "rff.fit(x_train, y_train)\n",
        "y_pred = rff.predict(x_test)\n",
        "\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RFFP (PCA: True, Time:  197.71152007199998\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8631"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGjLOtB5OlNT"
      },
      "source": [
        "**Время обучения RFF with PCA**: 197.71 sec\n",
        "\n",
        "**Полученная точность на тесте**: 0.8631"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYqQUEi-K-hU"
      },
      "source": [
        "__Задание 2. (3 балла)__\n",
        "\n",
        "Сравните подход со случайными признаками с обучением SVM на исходных признаках. Попробуйте вариант с обычным (линейным) SVM и с ядровым SVM. Ядровой SVM может очень долго обучаться, поэтому можно делать любые разумные вещи для ускорения: брать подмножество объектов из обучающей выборки, например.\n",
        "\n",
        "Сравните подход со случайными признаками с вариантом, в котором вы понижаете размерность с помощью PCA и обучаете градиентный бустинг. Используйте одну из реализаций CatBoost/LightGBM/XGBoost, не забудьте подобрать число деревьев и длину шага.\n",
        "\n",
        "Сделайте выводы — насколько идея со случайными признаками работает? Сравните как с точки зрения качества, так и с точки зрения скорости обучения и применения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1WS5MVMPUHa"
      },
      "source": [
        "##RFF vs SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN8LUlJgK-hV"
      },
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "def get_svc_score(X_train, X_test, y_train, y_test, kernel:str='linear'):\n",
        "  '''\n",
        "  function to train SVC and estimate fitted model\n",
        "  '''\n",
        "  assert kernel in ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "  start = timeit.default_timer()  \n",
        "  clf = make_pipeline(Normalizer(), SVC(kernel=kernel))\n",
        "  clf.fit(X_train, y_train)\n",
        "  stop = timeit.default_timer()\n",
        "  y_test = clf.predict(X_test)\n",
        "  print(f'SVC (Kernel {kernel}): {accuracy_score(y_test, y_pred)}. Time: {stop-start}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HgAsq8ie98H",
        "outputId": "f2a54fd4-3c49-443c-b9fa-c846d21ba3f3"
      },
      "source": [
        "get_svc_score(x_train, x_test, y_train, y_test, kernel='linear')\n",
        "get_svc_score(x_train, x_test, y_train, y_test, kernel='rbf')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVC (Kernel linear): 0.8989. Time: 820.4229728209993\n",
            "SVC (Kernel rbf): 0.9274. Time: 797.6187836219997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6IHPEVkP6Mq"
      },
      "source": [
        "**Итог:** \n",
        "\n",
        "При прочих равных SVC показывает результаты немногим выше, чем RFF. Однако время обучения SVC в 7-8 раз больше, чем RFF.\n",
        "Какую модель выбрать - зависит от требований к задаче."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esaX5zGMSkm5"
      },
      "source": [
        "## RFF vs XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDn0obs8fqDL",
        "outputId": "73c0b72e-ee29-4cf1-a5e6-0a0860747691"
      },
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "xgb_clf = xgb.XGBClassifier()\n",
        "start = timeit.default_timer()\n",
        "xgb_clf.fit(x_train, y_train)\n",
        "stop = timeit.default_timer()\n",
        "y_test = xgb_clf.predict(x_test)\n",
        "print(f'XGBoost: {accuracy_score(y_test, y_pred)}, Time: {stop-start}')ы"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost: 0.8882, Time: 960.4361493780002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGW-3ODnR3HR",
        "outputId": "301be459-141d-48a7-ea84-46dbe758dbde"
      },
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "#C нормализованными данными\n",
        "start = timeit.default_timer()  \n",
        "xgb_clf = make_pipeline(Normalizer(), xgb.XGBClassifier())\n",
        "xgb_clf.fit(x_train, y_train)\n",
        "stop = timeit.default_timer()\n",
        "y_test = xgb_clf.predict(x_test)\n",
        "print(f'XGBoost: {accuracy_score(y_test, y_pred)}, Time: {stop-start}')\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost: 0.8946, Time: 1927.8936499070005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqzqWyWcaH7i"
      },
      "source": [
        "**Итог:**\n",
        " Качество модели +- одинаково, однако скорость обучения RFF значительно ниже."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6umjhWuK-hV"
      },
      "source": [
        "__Задание 3. (2 балла)__\n",
        "\n",
        "Проведите эксперименты:\n",
        "1. Помогает ли предварительное понижение размерности с помощью PCA? \n",
        "2. Как зависит итоговое качество от n_features? Выходит ли оно на плато при росте n_features?\n",
        "3. Важно ли, какую модель обучать — логистическую регрессию или SVM?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bo6zVTdSvfx"
      },
      "source": [
        "## PCA Trus vs PCA False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2QIHIMbK-hW",
        "outputId": "96dd4918-1035-45b3-cca1-b097b45c56c9"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "rff = RFFPipeline(use_PCA=True)\n",
        "rff.fit(x_train, y_train)\n",
        "y_pred_pca = rff.predict(x_test)\n",
        "\n",
        "rff = RFFPipeline(use_PCA=False)\n",
        "rff.fit(x_train, y_train)\n",
        "y_pred_no_pca = rff.predict(x_test)\n",
        "\n",
        "\n",
        "print(f'RFF with PCA: {accuracy_score(y_test, y_pred_pca)}\\nRFF without PCA: {accuracy_score(y_test, y_pred_no_pca)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RFFP (PCA: True, Time:  200.70620892599982\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RFFP (PCA: False, Time:  1227.2595537019997\n",
            "RFF with PCA: 0.865\n",
            "RFF without PCA: 0.8651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iqz1_Cv7S3B7"
      },
      "source": [
        "**Итог:**\n",
        "\n",
        "Время обучения RFF с понижением размерности PCA: *200.7 sec*\n",
        "\n",
        "Время обучения RFF без понижения размерности PCA: *1227.26 sec*\n",
        "\n",
        "Точность модели RFF с понижением размерности PCA: *0.865*\n",
        "\n",
        "Точность модели RFF без понижения размерности PCA: *0.8651*\n",
        "\n",
        "\n",
        "То есть точностьсть модели на одном уровне, однако время обучения модели с понижением размерности в 6 раз меньше."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot1bTtQUUbkZ"
      },
      "source": [
        "## n_fetures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtEGMmK7oxc0",
        "outputId": "d389658e-c9da-45f3-d098-39fffcff1bac"
      },
      "source": [
        "num_dims = [1, 5, 10, 50, 100, 150, 200]\n",
        "acc = []\n",
        "for new_dim in num_dims:\n",
        "  rff = RFFPipeline(use_PCA=True, new_dim=new_dim)\n",
        "  rff.fit(x_train, y_train)\n",
        "  y_pred = rff.predict(x_test)\n",
        "  acc.append(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RFFP (PCA: True, Time:  83.03456619200006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RFFP (PCA: True, Time:  96.20104897999954\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RFFP (PCA: True, Time:  106.60732110499885\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RFFP (PCA: True, Time:  196.863525398001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RFFP (PCA: True, Time:  270.29699275200073\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RFFP (PCA: True, Time:  324.7796141309991\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RFFP (PCA: True, Time:  400.9261740480015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "LUaa5fvcKuYk",
        "outputId": "a4f324af-4dd2-42fe-a061-6c56df491234"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(num_dims, acc)\n",
        "plt.xlabel('n_features')\n",
        "plt.ylabel('accuracy')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'accuracy')"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7GFaEl8Upgg"
      },
      "source": [
        "**Итог:**\n",
        "\n",
        "Как видно до ~50 признаков скор модели растет, однако после 50 выходит на плато => можно выбирать наименьшее возможное количество фичей, удовлетворяющих получению высокой точности модели, с целью сократить время обучения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZXGIHCdVYHw"
      },
      "source": [
        "## LogReg vs SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uk19qktaL-dD",
        "outputId": "de31882c-7aae-4321-df0a-fce9d741640f"
      },
      "source": [
        "rff_lr = RFFPipeline(classifier='logreg')\n",
        "rff_lr.fit(x_train, y_train)\n",
        "y_pred_lr = rff_lr.predict(x_test)\n",
        "\n",
        "rff_svc = RFFPipeline(classifier='svc')\n",
        "rff_svc.fit(x_train, y_train)\n",
        "y_pred_svc = rff_svc.predict(x_test)\n",
        "\n",
        "\n",
        "print(f'RFF LogReg: {accuracy_score(y_test, y_pred_lr)}\\nRFF SVC: {accuracy_score(y_test, y_pred_svc)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RFFP (PCA: True, Time:  199.28721273600058\n",
            "[LibSVM]RFFP (PCA: True, Time:  1039.6394152360008\n",
            "RFF LogReg: 0.8659\n",
            "RFF SVC: 0.8727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHc3jndOV9EH"
      },
      "source": [
        "**Итог:**\n",
        "\n",
        "Как видно - качество модели RFF не зависит от выбора модели, но выбор модели сильно влияет на скорость обучения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJqXVuasK-hW"
      },
      "source": [
        "### Бонус"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVDWHCdrK-hX"
      },
      "source": [
        "__Задание 4. (Максимум 2 балла)__\n",
        "\n",
        "Как вы, должно быть, помните с курса МО-1, многие алгоритмы машинного обучения работают лучше, если признаки данных некоррелированы. Оказывается, что для RFF существует модификация, позволяющая получать ортогональные случайные признаки (Orthogonal Random Features, ORF). Об этом методе можно прочитать в [статье](https://proceedings.neurips.cc/paper/2016/file/53adaf494dc89ef7196d73636eb2451b-Paper.pdf). Реализуйте класс для вычисления ORF по аналогии с основным заданием. Обратите внимание, что ваш класс должен уметь работать со случаем n_features > new_dim (в статье есть замечание на этот счет). Проведите эксперименты, сравнивающие RFF и ORF, сделайте выводы."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSxvGI9iK-hX"
      },
      "source": [
        "# Your code here: (￣▽￣)/♫•*¨*•.¸¸♪"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pc7-1jmK-hY"
      },
      "source": [
        "__Задание 5. (Максимум 2 балла)__\n",
        "\n",
        "Поэкспериментируйте с функциями для вычисления новых случайных признаков. Не обязательно использовать косинус от скалярного произведения — можно брать знак от него, хэш и т.д. Придумайте побольше вариантов для генерации признаков и проверьте, не получается ли с их помощью добиваться более высокого качества. Также можете попробовать другой классификатор поверх случайных признаков, сравните результаты."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWj-O2vjK-hY"
      },
      "source": [
        "# Your code here: (￣▽￣)/♫•*¨*•.¸¸♪"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}